{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "# %pip install numpy\n",
    "# %pip install pandas\n",
    "# %pip install scikit-learn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 'Vignesh' 20.0 'Male' 50000.0 'India']\n",
      " [2 'Dhanush' 34.0 'Male' 60000.0 'USA']\n",
      " [3 'Eswar' nan 'Male' 45000.0 'UK']\n",
      " [4 'Sirisha' 29.0 'Female' nan 'India']\n",
      " [5 'Fakruddin' 40.0 'Male' 70000.0 'UK']\n",
      " [6 'Harshitha' 22.0 'Female' 38000.0 'USA']\n",
      " [7 'Sumanth' 35.0 'Male' 52000.0 'India']\n",
      " [8 'Anusha' 27.0 'Female' 48000.0 'UK']\n",
      " [9 'Afzal' 30.0 'Male' nan 'USA']\n",
      " [10 'Pavan' nan 'Male' 55000.0 'India']]\n",
      "['Yes' 'No' 'Yes' 'No' 'Yes' 'No' 'Yes' 'Yes' 'Yes' 'No']\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('Preprocessing.csv')\n",
    "x = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 6].values\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling missing values for Age column\n",
      "[[1 'Vignesh' 20.0 'Male' 50000.0 'India']\n",
      " [2 'Dhanush' 34.0 'Male' 60000.0 'USA']\n",
      " [3 'Eswar' 29.625 'Male' 45000.0 'UK']\n",
      " [4 'Sirisha' 29.0 'Female' nan 'India']\n",
      " [5 'Fakruddin' 40.0 'Male' 70000.0 'UK']\n",
      " [6 'Harshitha' 22.0 'Female' 38000.0 'USA']\n",
      " [7 'Sumanth' 35.0 'Male' 52000.0 'India']\n",
      " [8 'Anusha' 27.0 'Female' 48000.0 'UK']\n",
      " [9 'Afzal' 30.0 'Male' nan 'USA']\n",
      " [10 'Pavan' 29.625 'Male' 55000.0 'India']]\n",
      "Handling missing values for Salary column\n",
      "[[1 'Vignesh' 20.0 'Male' 50000.0 'India']\n",
      " [2 'Dhanush' 34.0 'Male' 60000.0 'USA']\n",
      " [3 'Eswar' 29.625 'Male' 45000.0 'UK']\n",
      " [4 'Sirisha' 29.0 'Female' 52250.0 'India']\n",
      " [5 'Fakruddin' 40.0 'Male' 70000.0 'UK']\n",
      " [6 'Harshitha' 22.0 'Female' 38000.0 'USA']\n",
      " [7 'Sumanth' 35.0 'Male' 52000.0 'India']\n",
      " [8 'Anusha' 27.0 'Female' 48000.0 'UK']\n",
      " [9 'Afzal' 30.0 'Male' 52250.0 'USA']\n",
      " [10 'Pavan' 29.625 'Male' 55000.0 'India']]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Select only the numeric columns for imputation\n",
    "\n",
    "# imputation for Age column\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "x[:, 2:3] = imputer.fit_transform(x[:, 2:3])\n",
    "print(\"Handling missing values for Age column\")\n",
    "print(x)\n",
    "# imputation for Salary column\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "x[:, 4:5] = imputer.fit_transform(x[:, 4:5])\n",
    "print(\"Handling missing values for Salary column\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Independent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding the Country column\n",
      "[[1.0 0.0 0.0 1 'Vignesh' 20.0 'Male' 50000.0]\n",
      " [0.0 0.0 1.0 2 'Dhanush' 34.0 'Male' 60000.0]\n",
      " [0.0 1.0 0.0 3 'Eswar' 29.625 'Male' 45000.0]\n",
      " [1.0 0.0 0.0 4 'Sirisha' 29.0 'Female' 52250.0]\n",
      " [0.0 1.0 0.0 5 'Fakruddin' 40.0 'Male' 70000.0]\n",
      " [0.0 0.0 1.0 6 'Harshitha' 22.0 'Female' 38000.0]\n",
      " [1.0 0.0 0.0 7 'Sumanth' 35.0 'Male' 52000.0]\n",
      " [0.0 1.0 0.0 8 'Anusha' 27.0 'Female' 48000.0]\n",
      " [0.0 0.0 1.0 9 'Afzal' 30.0 'Male' 52250.0]\n",
      " [1.0 0.0 0.0 10 'Pavan' 29.625 'Male' 55000.0]]\n",
      "\n",
      "Encoding the Gender column\n",
      "[[1.0 0.0 0.0 1 'Vignesh' 20.0 1 50000.0]\n",
      " [0.0 0.0 1.0 2 'Dhanush' 34.0 1 60000.0]\n",
      " [0.0 1.0 0.0 3 'Eswar' 29.625 1 45000.0]\n",
      " [1.0 0.0 0.0 4 'Sirisha' 29.0 0 52250.0]\n",
      " [0.0 1.0 0.0 5 'Fakruddin' 40.0 1 70000.0]\n",
      " [0.0 0.0 1.0 6 'Harshitha' 22.0 0 38000.0]\n",
      " [1.0 0.0 0.0 7 'Sumanth' 35.0 1 52000.0]\n",
      " [0.0 1.0 0.0 8 'Anusha' 27.0 0 48000.0]\n",
      " [0.0 0.0 1.0 9 'Afzal' 30.0 1 52250.0]\n",
      " [1.0 0.0 0.0 10 'Pavan' 29.625 1 55000.0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [5])], remainder='passthrough')\n",
    "x = ct.fit_transform(x)\n",
    "print(\"\\nEncoding the Country column\")\n",
    "print(x)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "x[:, 6] = le.fit_transform(x[:, 6])\n",
    "print(\"\\nEncoding the Gender column\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding the Purchased column\n",
      "[1 0 1 0 1 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "print(\"\\nEncoding the Purchased column\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting the dataset into training and testing sets\n",
      "x_train\n",
      "[[0.0 1.0 0.0 5 'Fakruddin' 40.0 1 70000.0]\n",
      " [1.0 0.0 0.0 1 'Vignesh' 20.0 1 50000.0]\n",
      " [1.0 0.0 0.0 4 'Sirisha' 29.0 0 52250.0]\n",
      " [0.0 0.0 1.0 2 'Dhanush' 34.0 1 60000.0]\n",
      " [0.0 1.0 0.0 8 'Anusha' 27.0 0 48000.0]\n",
      " [0.0 0.0 1.0 9 'Afzal' 30.0 1 52250.0]\n",
      " [0.0 0.0 1.0 6 'Harshitha' 22.0 0 38000.0]]\n",
      "\n",
      "x_test\n",
      "[[0.0 1.0 0.0 3 'Eswar' 29.625 1 45000.0]\n",
      " [1.0 0.0 0.0 10 'Pavan' 29.625 1 55000.0]\n",
      " [1.0 0.0 0.0 7 'Sumanth' 35.0 1 52000.0]]\n",
      "\n",
      "y_train\n",
      "[1 1 0 0 1 1 0]\n",
      "\n",
      "y_test\n",
      "[1 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3,random_state=1)\n",
    "print(\"\\nSplitting the dataset into training and testing sets\")\n",
    "print(\"x_train\")\n",
    "print(x_train)\n",
    "\n",
    "print(\"\\nx_test\")\n",
    "print(x_test)\n",
    "\n",
    "print(\"\\ny_train\")\n",
    "print(y_train)\n",
    "\n",
    "print(\"\\ny_test\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Scaling\n",
      "x_train\n",
      "[[0.0 1.0 0.0 5 'Fakruddin' 1.7591498917973942 1 1.8468680746410224]\n",
      " [1.0 0.0 0.0 1 'Vignesh' -1.3982986319415185 1 -0.3168267408379995]\n",
      " [1.0 0.0 0.0 4 'Sirisha' 0.022553203740992154 0 -0.07341107409660956]\n",
      " [0.0 0.0 1.0 2 'Dhanush' 0.8119153346757203 1 0.7650206669015114]\n",
      " [0.0 1.0 0.0 8 'Anusha' -0.2931916486328991 0 -0.5331962223859017]\n",
      " [0.0 0.0 1.0 9 'Afzal' 0.1804256299279378 1 -0.07341107409660956]\n",
      " [0.0 0.0 1.0 6 'Harshitha' -1.0825537795676272 0 -1.6150436301254127]]\n",
      "\n",
      "x_test\n",
      "[[0.0 1.0 0.0 3 'Eswar' 0.12122347010783317 1 -0.857750444707755]\n",
      " [1.0 0.0 0.0 10 'Pavan' 0.12122347010783317 1 0.22409696303175594]\n",
      " [1.0 0.0 0.0 7 'Sumanth' 0.9697877608626659 1 -0.10045725929009733]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "# Only numerical features (Age, Salary) need scaling\n",
    "x_train[:, [5,7]] = sc.fit_transform(x_train[:, [5,7]])\n",
    "x_test[:, [5,7]] = sc.transform(x_test[:, [5,7]])\n",
    "print(\"\\nFeature Scaling\")\n",
    "print(\"x_train\")\n",
    "print(x_train)\n",
    "print(\"\\nx_test\")\n",
    "print(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
